<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width-device-width, initial-scale=1.0" />
    <title>Neural Network Models</title>
    <link rel="shortcut icon" type="image/x-icon" href="static/icon.ico" />

    <!-- Import Bootstrap CSS -->
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.1/dist/css/bootstrap.min.css"
      rel="stylesheet"
      integrity="sha384-iYQeCzEYFbKjA/T2uDLTpkwGzCiq6soy8tYaI1GyVh/UjpbCx/TYkiZhlZB6+fzT"
      crossorigin="anonymous"
    />

    <!-- Import Our CSS -->
    <link rel="stylesheet" href="static/css/styles.css" />
  </head>

  <body>
    <!-- Create Navigation Bar-->
    <div class="navigation">
      <nav class="navbar navbar-expand-lg navbar-light">
        <div class="navbar-header">
          <a class="navbar-brand" href="index.html">
            <img style="max-width:80px; margin-top: -7px; margin-left:2px;" src="static/img/abalone_shell.png">
          </a>
        </div>
        <div
          class="collapse navbar-collapse justify-content-center"
          id="navbarNav"
        >
        <ul class="navbar-nav">
          <li class="nav-item">
            <a class="nav-link" href="index.html">Home</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="overview.html">Overview</a>
          </li>
          <li>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation">
              <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNavDropdown">
              <ul class="navbar-nav">
                <li class="nav-item dropdown">
                  <a class="nav-link dropdown-toggle" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false">
                    Models
                  </a>
                  <ul class="dropdown-menu">
                    <li><a class="dropdown-item" href="regression.html">Multiple Linear Regression</a></li>
                    <li><a class="dropdown-item" href="advancedregressors.html">Advanced Regressors</a></li>
                    <li><a class="dropdown-item" href="network.html">Neural Network</a></li>
                  </li>
                  </ul>
             <li class="nav-item">
              <a class="nav-link" href="analysis.html">Data Visualizations</a>
             </li>
            <li class="nav-item">
              <a class="nav-link" href="summary.html">Conclusion</a>
            </li>
          </ul>
        </div>
      </nav>
    </div>

    <div class="jumbotron text-center">
      <h1>Predicting Ages of Abalone</h1>
    </div>
    <!-- <br />
    <div class="row justify-content-center">
      <img class="center-block" src="static/img/abalone_shell.png" />
    </div>
    <br />
    <br /> -->
    <div class='tableauPlaceholder2' id='viz1670315680798' style='position: relative'><noscript><a href='#'><img alt='Dashboard 1 ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;R2&#47;R2valuesofeachNeuralNetwork&#47;Dashboard1&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='R2valuesofeachNeuralNetwork&#47;Dashboard1' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;R2&#47;R2valuesofeachNeuralNetwork&#47;Dashboard1&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en-US' /><param name='filter' value='publish=yes' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1670315680798');                    var vizElement = divElement.getElementsByTagName('object')[0];                    if ( divElement.offsetWidth > 800 ) { vizElement.style.width='1020px';vizElement.style.minHeight='587px';vizElement.style.maxHeight='887px';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.width='1020px';vizElement.style.minHeight='587px';vizElement.style.maxHeight='887px';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';} else { vizElement.style.width='100%';vizElement.style.height='727px';}                     var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>

    <div class="container">
      <div class="jumbotron text-center">
        <h2>Details:</h2>
      </div>
      <div class="row justify-content-center">
        <div class="span4">
          
          <p>
            Neural Network #1 - In our first neural network model, we set up a network with one hidden 
            layer of 30 densely-connected perceptrons with ReLU activation, and an output layer of one 
            perceptron with a linear activation. We trained this model for 50 epochs before testing it 
            on the test data set. We used Mean Squared Error (MSE) as our loss function, as we trying 
            solve a regression problem rather than a classification problem. The output layer has a 
            linear activation instead of a sigmoid activation for the same reason.

            This model produced an R<sup>2</sup> value of 51.172%. This is on par with the 
            performance of the Multiple Linear Regression models, and provides a good starting point. <br>
          </p>
          <p>
            Neural Network #2 - For our first attempt at improving the neural network model, we added a 
            second hidden layer. This hidden layer is identical to the first, with 30 densely-connected 
            perceptrons with a ReLU activation.
            
            This increased our R<sup>2</sup> value to 55.309%. So far, this model explains the most variance in 
            the data.
          </p>
            Neural Network #3 - For our third model, we removed the sex indicator columns to see if 
            that would improve our model. Our hypothesis was that the sex indicators could be a 
            confounding factor to our model. We used the same model structure as we did for the 
            Neural Network #2.

            This resulted in an R<sup>2</sup> value of 49.901%. This is indicative to us that the sex 
            indicator columns improve the model's performance.
          <p>
            <br>
            Neural Network #4 - In our fourth model, we used the same network structure as Neural 
            Network #2, but we increased the number of epochs that the model trained on the training 
            set from 50 to 100 epochs.
            
            This resulted in an R<sup>2</sup> value of 55.843%, which was a bit of a decrease from the 
            performance of the original Neural Network #2.
            
          </p>
            Neural Network #5 - In our fifth model, we added a third hidden layer to our model. This model consists of three layers of 30 densely-connected perceptrons with ReLU activation functions.

            This model produced an R<sup>2</sup> value of 59.190%. This is the best-performing model so far!
          <p>
            <br>
            Neural Network #6 - For our sixth neural network model, we took the same parameters as #5, but increased the number of epochs that the model would be trained on to 75; this returned with a R<sup>2</sup>> value of 58.178%.
           <br>
           <br>
            Neural Network #7 - For our seventh model, we tried adding a fourth hidden layer in hopes that the new layer would increase performance of the model. The model returned an R<sup>2</sup>> score of 56.535%. As this model did not perform as well as the previous model with three layers, we decided to look at another approach to improve the performance of our neural networks: Keras Tuner.

          </p>
          <div class="jumbotron text-center">
            <h3>Keras Tuner:</h3>
          </div>
          <p>
            We believed that Keras Tuner would be a much more efficient method of testing various different neural network models without having to create each one by ourselves and find the best one using trial and error. We gave all of the Keras Tuner related models the option to try both ReLU and Hyperbolic Tangent activation functions. Once again the models are using Mean Absolute Error as a loss function / evaluation metric, as we are performing a regression.

            The Keras Tuner model will also have a varied number of perceptrons in the hidden layer, going from 1 to 30 nodes.

            <br>
            <br>
            Neural Network #8 - Our first model made with Keras Tuner gave us an R<sup>2</sup> value of 38.824%, which is a lot worse than our previous neural network models. This pushed us to try more complex Keras Tuner models.
          </p>
          <p>
            Neural Network #9 - In our second Keras Tuner model, we added a second densely-connected hidden layer with ReLU activation. Our thought process was that adding more layers to the previous Keras Tuner model would return us with more favorable results. The model returned to us an R<sup>2</sup> score of -2,915.8%. This is a clear indication that this model does not fit the data well, as R<sup>2</sup> values should be a positive number between 0 and 1.
            <br>

          </p>
          <p>
            Neural Network #10 - In this model we attempt to get valid results from Keras Tuner by increasing the number of training epochs that the model recieves before being evaluated to 50. This results in an R<sup>2</sup> value of -206.08%, which is a massive improvement from the last model that was tested, but still indicated that the model does not fit the data.
          <br>
          </p>
          <p>
            Neural Network #11 - In a final, last-ditch effort to improve our Keras Tuner model, we increased the number of training epochs to 75. This resulted in an R<sup>2</sup> value of -487.64%. This indicates again, that this model does not work with our data.
          </p>
          <p>
            After some discourse with one of our TAs (thank you for all of your help Colin!), we found that the Keras Tuner 'Hyperband' tuner that we were using does not allow you to pick your own batch size. We did some tests where we took the parameters of our Keras Tuner models and put them into our first neural nework model, and we did not recieve the same invalid R<sup>2</sup> scores that we recieved with the Keras Tuner models. The only difference between the two models was the batch size, leading us to conclude that perhaps if we were able to choose our own batch size for the Hyberband tuner models, we may have had more favorable results. 
            <br>
            <br>
            One option in a case like this would be to build our own class of tuner, where we would be able to fine-tune the batch size to our liking. We decided that learning how to build our own Keras Tuner class from scratch was not a feasible task for this project due to the limited time frame alloted to us, and the time we had already spent bumbling around with the Hyperband tuner in search of valid results.
          </p>
        </div>
      </div>
    </div>
   
  

    <!-- Bootstrap JavaScript -->
    <script
      src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.1/dist/js/bootstrap.bundle.min.js"
      integrity="sha384-u1OknCvxWvY5kfmNBILK2hRnQC3Pr17a+RTT6rIHI7NnikvbZlHgTPOOmMi466C8"
      crossorigin="anonymous"
    ></script>
  </body>
</html>
